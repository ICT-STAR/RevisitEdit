alg_name: "WISE"
model_name: "./hugging_cache/mistral-7b"
device: 1

mask_ratio: 0.2
edit_lr: 1.0
n_iter: 70
norm_constraint: 1.0
act_margin: [5.0, 20.0, 10.0] # alpha, beta, gamma
act_ratio: 0.88
save_freq: 500
merge_freq: 1000
merge_alg: 'ties'
objective_optimization: 'only_label'
inner_params:
- model.layers[27].mlp.down_proj.weight


## alternative: WISE-Merge, WISE-Retrieve

# for merge (if merge)
densities: 0.53
weights: 1.0

# for retrieve (if retrieve, pls set to True)
retrieve: True
replay: False # True --> will replay the past editing instances: see https://arxiv.org/abs/2405.14768 Appendix B.3

model_parallel: False

# for save and load
# save_path: "./wise_checkpoint/wise.pt"
# load_path: "./wise_checkpoint/wise.pt"

# evaluation
# "traditional" for the evaluation of EasyEdit: context-free, teacher-forcing, ground truth length, match ratio
# "real-world" for the evaluation in our paper: context-guided, autoregressive decoding, natural stop criteria, LLM-as-a-Judge
evaluation_framework: "real-world"  
# for real-world evaluation in our paper, you need to set
context_type: "question-only"  # "qa_inst" for QA task instruction; "chat_temp" for chat model; default config is question-only
metric_type: "exact_match"  # "exact_match" or "llm_judge"
api_key: "xxxxx"  # Openai api key for llm judge (GPT-4o-mini)